{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUses the model to predict known values in order to evaluate the model (with AUC scoring).\\n\\n@author(s): Martin Guy\\n\\nLast modified: July 9, 2016\\n\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Uses the model to predict known values in order to evaluate the model (with AUC scoring).\n",
    "\n",
    "@author(s): Martin Guy\n",
    "\n",
    "Last modified: July 9, 2016\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics, cross_validation\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#declaring some parameters\n",
    "subjects = range(1,13)\n",
    "training_size = 0.55\n",
    "cols = ['HandStart','FirstDigitTouch',    #class names\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Process on a fixed subject, classifier and training size\n",
    "#returns the average auc score of the subject\n",
    "def process(subject,clf, training_size, show=False, export=True, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"#Â Begin process of subject %d\" % (subject))\n",
    "        print(\"Chargement du signal d'entrainement...\")\n",
    "    \n",
    "    #We use here already filtered signals.\n",
    "    #Signals were filtered using Alexandre Barachant's \"Beat the benchmark\" code\n",
    "    filename = \"train_filtered/filtered_\"+str(subject)+\".npz\"\n",
    "    datas = np.load(filename)\n",
    "    feattr = datas['arr_0']\n",
    "    labels = datas['arr_1']\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "\n",
    "    nbExemples = feattr.shape[1]\n",
    "    \n",
    "    X_train, X_test, labels_train, labels_test = cross_validation.train_test_split(feattr.T, labels.T, test_size=(1.0-training_size), random_state=0)\n",
    "    \n",
    "    nbTrain = len(X_train)\n",
    "    nbTest = len(X_test)\n",
    "\n",
    "    ################ Train classifiers ########################################\n",
    "     \n",
    "    clf_list = [] #classifiers list\n",
    "    clf_name = clf\n",
    "    clf_name_info = \"\"\n",
    "    clf_names = [\"LogisticRegression\", \"GaussianNB\", \"6Neighbor\"]\n",
    "    \n",
    "    if clf == \"LogisticRegression\":\n",
    "        clf_list = [LogisticRegression() for i in range(6)]\n",
    "        clf_name_info = \"Logistic Regression\"\n",
    "    elif clf == \"GaussianNB\":\n",
    "        clf_list = [GaussianNB() for i in range(6)]\n",
    "        clf_name_info = \"Gaussian Naive Bayesian\"\n",
    "    elif clf == \"6Neighbor\":\n",
    "        clf_list = [KNeighborsClassifier(6) for i in range(6)]\n",
    "        clf_name_nfo = \"6-Nearest Neighbors\"\n",
    "    else:\n",
    "        print(\"Error: you must select an appropriate classifier :\", clf_names)\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    for i in range(6):\n",
    "        if verbose:\n",
    "            print('Train subject %d, class %s(%d)' % (subject, cols[i], i))\n",
    "        clf_list[i].fit(X_train,labels_train.T[i])\n",
    "\n",
    "\n",
    "\n",
    "    ################ Evaluate classifier ########################################\n",
    "    avg_auc = 0 #average auc\n",
    "\n",
    "    #pour chaque classe\n",
    "    for i in range(6):\n",
    "        preds = clf_list[i].predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(labels_test.T[i], preds)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        avg_auc += auc\n",
    "\n",
    "        label_name = cols[i] + \" - AUC : \" + str(auc)\n",
    "        plt.plot(fpr,tpr, label=label_name, lw=2)\n",
    "\n",
    "    avg_auc /= 6\n",
    "    global_auc = avg_auc\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Average auc :\", avg_auc)\n",
    "    \n",
    "    \n",
    "    ################ Plot Configuration ########################################\n",
    "    \n",
    "    if export or show:\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "\n",
    "        title = \"Subject \" + str(subject) + \" ROC, average auc : \" + str(avg_auc) + \" using \" + clf_name_info + \" and learning \" +\\\n",
    "        str(nbTrain) + \" examples\"\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot([0,1],[0,1])\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(15.5, 10.5)\n",
    "        plt.legend(loc=4, borderaxespad=0.)\n",
    "    \n",
    "    savepath = 'evaluation/'+ clf_name +'_subject_'+str(subject) +'_different_classifier_' + str(training_size) + '.png'\n",
    "\n",
    "    ################ Plot printing ########################################\n",
    "    if export:\n",
    "        plt.savefig(savepath)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    ################ Score writing ########################################\n",
    "    if export:\n",
    "        with open('evaluation/avg_auc.txt', 'a') as f:\n",
    "            f.write('(' + str(subject) + ')' + clf_name_info + \" : \" + str(global_auc) + \" (learning = \" + str(nbTrain) + \")\\n\")\n",
    "    \n",
    "    return avg_auc\n",
    "\n",
    "nbSubjects = len(subjects)\n",
    "\n",
    "#Evaluate a classifier for a given training size list\n",
    "#returns the matrix of auc scores for each training size and each subject\n",
    "def process_all_tr(name,training_size_list, verbose = False):\n",
    "    \"\"\"\n",
    "    Evaluate a classifier for a given training size list\n",
    "    \"\"\"\n",
    "    n = len(training_size_list)\n",
    "    results = np.zeros((nbSubjects, n))\n",
    "    #for each training_rate\n",
    "    for (index,tr) in enumerate(training_size_list):\n",
    "        if verbose:\n",
    "            print(\"\\n**** Begin with training rate : %0.2f ****\" % (tr))\n",
    "        #process on all subjects\n",
    "        for subject in subjects:\n",
    "            results[subject-1][index] = process(subject, name, training_size = tr, export = False, verbose=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def arrondi(val):\n",
    "    return (\"%.3f\" % val)\n",
    "\n",
    "#Ne pas oublier d'utiliser:\n",
    "#\\usepackage{array}\n",
    "\n",
    "#\\begin{tabular}{|l|c|r|}\n",
    "#  \\hline\n",
    "#  colonne 1 & colonne 2 & colonne 3 \\\\\n",
    "#  \\hline\n",
    "#  1.1 & 1.2 & 1.3 \\\\\n",
    "#  2.1 & 2.2 & 2.3 \\\\\n",
    "#  \\hline\n",
    "#\\end{tabular}\n",
    "\n",
    "def exportToLatex(results, colonnes, filename, clfname, mode='w'):\n",
    "    \n",
    "    for i in subjects:\n",
    "        results[i-1] = map(arrondi, results[i-1])\n",
    "    \n",
    "    def writeLine(numSubject, f):\n",
    "        \n",
    "        valmax = max(results[numSubject])\n",
    "        \n",
    "        f.write(str(numSubject+1))\n",
    "        for (i,col) in enumerate(results[numSubject]):\n",
    "            f.write(\" & \")\n",
    "            \n",
    "            if(col == valmax):\n",
    "                f.write(\"\\\\textbf{\")\n",
    "            f.write(str(col))\n",
    "            if(col == valmax):\n",
    "                f.write(\"}\")\n",
    "        f.write(\" \\\\\\\\ \\n\")\n",
    "        f.write(\"\\hline \\n\")\n",
    "    \n",
    "    with open('export/'+filename+'.txt', mode) as f:\n",
    "        f.write(\"Results for\"+clfname+\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\\\begin{tabular}{|\")\n",
    "        f.write(\"c|\"*(len(colonnes)+1) + \"}\\n\")\n",
    "        f.write(\"\\hline \\n\")\n",
    "        \n",
    "        f.write(\"Subjects/Training size(\\%)\")\n",
    "        \n",
    "        for (i,col) in enumerate(colonnes):\n",
    "            f.write(\" & \")\n",
    "            f.write(str(int(col*100)))\n",
    "        f.write(\" \\\\\\\\ \\n\")\n",
    "        \n",
    "        f.write(\"\\hline \\n\")\n",
    "        \n",
    "        for i in subjects:\n",
    "            writeLine(i-1, f)\n",
    "        \n",
    "        f.write(\"\\end{tabular}\")\n",
    "        \n",
    "\n",
    "def exportToNPZ(filename, results):\n",
    "    np.savez_compressed(\"export/\"+filename+\".npz\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 6Neighbor\n",
      "\n",
      "**** Begin with training rate : 0.05 ****\n"
     ]
    }
   ],
   "source": [
    "training_size_list = [0.05, 0.10, 0.25, 0.50]\n",
    "\n",
    "clf_names = [\"6Neighbor\"]\n",
    "latexFilenames = ['6Neighbor']\n",
    "#clf_names = [\"LogisticRegression\", \"GaussianNB\", \"6Neighbor\"]\n",
    "\n",
    "nbClassifier = len(clf_names)\n",
    "n = len(training_size_list)\n",
    "\n",
    "\n",
    "results = np.empty((nbClassifier, nbSubjects, n))            \n",
    "\n",
    "for (i,clf) in enumerate(clf_names):\n",
    "    print(\"Starting with %s\" % (clf))\n",
    "    results[i] = process_all_tr(clf, training_size_list, verbose = True)\n",
    "    print(\"\")\n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(nbClassifier):\n",
    "    exportToLatex(results[i],training_size_list, latexFilenames[i], clf_names[i])\n",
    "    exportToNPZ(latexFilenames[i], results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colonnes = training_size_list\n",
    "lignes = subjects\n",
    "\n",
    "df_array = []\n",
    "\n",
    "for i in range(nbClassifier):\n",
    "    df_array.append(pd.DataFrame(results[i], index=lignes, columns=colonnes))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.04</th>\n",
       "      <th>0.05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761778</td>\n",
       "      <td>0.766674</td>\n",
       "      <td>0.769916</td>\n",
       "      <td>0.771192</td>\n",
       "      <td>0.772545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698553</td>\n",
       "      <td>0.705801</td>\n",
       "      <td>0.709761</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.713977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685777</td>\n",
       "      <td>0.693347</td>\n",
       "      <td>0.697662</td>\n",
       "      <td>0.699113</td>\n",
       "      <td>0.700601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815895</td>\n",
       "      <td>0.819860</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>0.822059</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.699108</td>\n",
       "      <td>0.706284</td>\n",
       "      <td>0.710310</td>\n",
       "      <td>0.711814</td>\n",
       "      <td>0.712819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.678286</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.693962</td>\n",
       "      <td>0.695973</td>\n",
       "      <td>0.696979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.773746</td>\n",
       "      <td>0.782086</td>\n",
       "      <td>0.786129</td>\n",
       "      <td>0.787994</td>\n",
       "      <td>0.789903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.793802</td>\n",
       "      <td>0.796224</td>\n",
       "      <td>0.797722</td>\n",
       "      <td>0.798432</td>\n",
       "      <td>0.798819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.690122</td>\n",
       "      <td>0.692788</td>\n",
       "      <td>0.693744</td>\n",
       "      <td>0.694724</td>\n",
       "      <td>0.694648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.732787</td>\n",
       "      <td>0.736358</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.739009</td>\n",
       "      <td>0.739721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.714122</td>\n",
       "      <td>0.719408</td>\n",
       "      <td>0.721477</td>\n",
       "      <td>0.721422</td>\n",
       "      <td>0.722218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.692291</td>\n",
       "      <td>0.703912</td>\n",
       "      <td>0.708658</td>\n",
       "      <td>0.710806</td>\n",
       "      <td>0.712157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.01      0.02      0.03      0.04      0.05\n",
       "1   0.761778  0.766674  0.769916  0.771192  0.772545\n",
       "2   0.698553  0.705801  0.709761  0.711800  0.713977\n",
       "3   0.685777  0.693347  0.697662  0.699113  0.700601\n",
       "4   0.815895  0.819860  0.821326  0.822059  0.822913\n",
       "5   0.699108  0.706284  0.710310  0.711814  0.712819\n",
       "6   0.678286  0.689552  0.693962  0.695973  0.696979\n",
       "7   0.773746  0.782086  0.786129  0.787994  0.789903\n",
       "8   0.793802  0.796224  0.797722  0.798432  0.798819\n",
       "9   0.690122  0.692788  0.693744  0.694724  0.694648\n",
       "10  0.732787  0.736358  0.737762  0.739009  0.739721\n",
       "11  0.714122  0.719408  0.721477  0.721422  0.722218\n",
       "12  0.692291  0.703912  0.708658  0.710806  0.712157"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Results for \", clf_names[0])\n",
    "df_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  GaussianNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.04</th>\n",
       "      <th>0.05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780274</td>\n",
       "      <td>0.781843</td>\n",
       "      <td>0.782289</td>\n",
       "      <td>0.782010</td>\n",
       "      <td>0.782720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.727767</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.727107</td>\n",
       "      <td>0.726944</td>\n",
       "      <td>0.725785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700206</td>\n",
       "      <td>0.702529</td>\n",
       "      <td>0.703325</td>\n",
       "      <td>0.703582</td>\n",
       "      <td>0.703465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.821848</td>\n",
       "      <td>0.823131</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.823803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.715015</td>\n",
       "      <td>0.713660</td>\n",
       "      <td>0.713203</td>\n",
       "      <td>0.713049</td>\n",
       "      <td>0.712685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700827</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702736</td>\n",
       "      <td>0.704917</td>\n",
       "      <td>0.704253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.781035</td>\n",
       "      <td>0.782244</td>\n",
       "      <td>0.782291</td>\n",
       "      <td>0.781915</td>\n",
       "      <td>0.782519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.805163</td>\n",
       "      <td>0.805249</td>\n",
       "      <td>0.805321</td>\n",
       "      <td>0.806124</td>\n",
       "      <td>0.806227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.685313</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.692095</td>\n",
       "      <td>0.692504</td>\n",
       "      <td>0.692707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.739375</td>\n",
       "      <td>0.739707</td>\n",
       "      <td>0.740322</td>\n",
       "      <td>0.740931</td>\n",
       "      <td>0.741466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.734859</td>\n",
       "      <td>0.735853</td>\n",
       "      <td>0.735576</td>\n",
       "      <td>0.735262</td>\n",
       "      <td>0.734932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.712091</td>\n",
       "      <td>0.712059</td>\n",
       "      <td>0.711848</td>\n",
       "      <td>0.712194</td>\n",
       "      <td>0.712209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.01      0.02      0.03      0.04      0.05\n",
       "1   0.780274  0.781843  0.782289  0.782010  0.782720\n",
       "2   0.727767  0.726900  0.727107  0.726944  0.725785\n",
       "3   0.700206  0.702529  0.703325  0.703582  0.703465\n",
       "4   0.821848  0.823131  0.823002  0.823847  0.823803\n",
       "5   0.715015  0.713660  0.713203  0.713049  0.712685\n",
       "6   0.700827  0.702089  0.702736  0.704917  0.704253\n",
       "7   0.781035  0.782244  0.782291  0.781915  0.782519\n",
       "8   0.805163  0.805249  0.805321  0.806124  0.806227\n",
       "9   0.685313  0.690000  0.692095  0.692504  0.692707\n",
       "10  0.739375  0.739707  0.740322  0.740931  0.741466\n",
       "11  0.734859  0.735853  0.735576  0.735262  0.734932\n",
       "12  0.712091  0.712059  0.711848  0.712194  0.712209"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Results for \", clf_names[1])\n",
    "df_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(\"evaluation/resultats (0.01to0.05_LR_and_GaussianNB).npz\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
